---

copyright:
  years: 2019, 2020
lastupdated: "2020-09-02"

subcollection: text-to-speech

---

{:shortdesc: .shortdesc}
{:external: target="_blank" .external}
{:tip: .tip}
{:important: .important}
{:note: .note}
{:deprecated: .deprecated}
{:pre: .pre}
{:codeblock: .codeblock}
{:screen: .screen}
{:javascript: .ph data-hd-programlang='javascript'}
{:java: .ph data-hd-programlang='java'}
{:python: .ph data-hd-programlang='python'}
{:swift: .ph data-hd-programlang='swift'}

# Research references
{: #references}

For more information about the research behind the {{site.data.keyword.texttospeechfull}} service, see the following documents. IBM researchers wrote or contributed to all of these papers.
{: shortdesc}

1.  <a id="eide2007" style="border-bottom:none">Eide, Ellen M., and Raul Fernandez.</a> [*Database Mining for Flexible Concatenative Text-to-Speech.*](http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=4218196){: external} Proceedings of International Conference on Acoustics, Speech and Signal Processing (ICASSP), Vol. 4 (2007): pp. 697-700.
1.  <a id="eide2006" style="border-bottom:none">Eide, Ellen, Raul Fernandez, Ron Hoory, Wael Hamza, Zvi Kons, Michael Picheny, Ariel Sagi, Slava Shechtman, and Zhi Wei Shuang.</a> [*The {{site.data.keyword.IBM_notm}} Submitted to the 2006 Blizzard Text-to-Speech Challenge.*](http://www.festvox.org/blizzard/bc2006/ibm_blizzard2006.pdf){: external} In Blizzard Challenge Workshop 2006.
1.  <a id="fernandez2015" style="border-bottom:none">Fernandez, Raul, Asaf Rendel, Bhuvana Ramabhadran, and Ron Hoory.</a> [*Using Deep Bidirectional Recurrent Neural Networks for Prosodic-Target Prediction in a Unit-Selection Text-to-Speech System.*](https://www.researchgate.net/publication/295080074_Using_Deep_Bidirectional_Recurrent_Neural_Networks_for_Prosodic-Target_Prediction_in_a_Unit-Selection_Text-to-Speech_System){: external} Proceedings Interspeech (2015), pp. 1606-1610.
1.  <a id="fernandez2014" style="border-bottom:none">Fernandez, Raul, Asaf Rendel, Bhuvana Ramabhadran, and Ron Hoory.</a> [*Prosody Contour Prediction with Long Short-Term Memory, Bi-directional, Deep Recurrent Neural Networks.*](https://www.researchgate.net/publication/267154161_Prosody_Contour_Prediction_with_Long_Short-Term_Memory_Bi-Directional_Deep_Recurrent_Neural_Networks){: external} Proceedings Interspeech (2014), pp. 2268-2272.
1.  <a id="fernandez2008" style="border-bottom:none">Fernandez, Raul, Zvi Kons, Slava Shechtman, Zhi Wei Shuang, Ron Hoory, Bhuvana Ramabhadran, and Yong Qin.</a> [*The {{site.data.keyword.IBM_notm}} Submitted to the 2008 Text-to-Speech Blizzard Challenge.*](http://festvox.org/blizzard/bc2008/ibm_Blizzard2008.pdf){: external} In Blizzard Challenge Workshop 2008.
1.  <a id="fernandez2007" style="border-bottom:none">Fernandez, Raul, and Bhuvana Ramabhadran.</a> [*Automatic Exploration of Corpus-Specific Properties for Expressive Text-to-Speech: A Case Study in Emphasis.*](http://www.isca-speech.org/archive_open/archive_papers/ssw6/ssw6_034.pdf){: external} Proceedings of the Sixth ISCA Workshop on Speech Synthesis (August 2007): pp. 34-39.
1.  <a id="fernandez2006" style="border-bottom:none">Fernandez, Raul, Raimo Bakis, Ellen Eide, Wael Hamza, John Pitrelli, and Michael A. Picheny.</a> [*The 2006 TC-STAR Evaluation of the {{site.data.keyword.IBM_notm}} Expressive Text-to-Speech Synthesis System.*](https://www.researchgate.net/publication/228787461_The_2006_TC-STAR_evaluation_of_the_IBM_text-to-speech_synthesis_system){: external} Speech-to-Speech Translation Workshop, Barcelona, Spain (2006), pp. 175-180.
1.  <a id="kons2019" style="border-bottom:none">Kons, Zvi, Slava Shechtman, Alex Sorin, Carmel Rabinovitz, and Ron Hoory.</a> [*High quality, lightweight and adaptable TTS using LPCNet.*](https://arxiv.org/abs/1905.00590){: external} Submitted to Interspeech (2019).
1.  <a id="pitrelli2006" style="border-bottom:none">Pitrelli, John F., Raimo Bakis, Ellen M. Eide, Raul Fernandez, Wael Hamza, and Michael A. Picheny.</a> [*The {{site.data.keyword.IBM_notm}} Expressive Text-to-Speech Synthesis System for American English.*](https://ieeexplore.ieee.org/document/1643639){: external} IEEE Transactions on Audio, Speech, and Language Processing, Vol. 14(4) (July 2006): pp. 1099-1108.
1.  <a id="rendel2016" style="border-bottom:none">Rendel, Asaf, Raul Fernandez, Ron Hoory, and Bhuvana Ramabhadran.</a> [*Using Continuous Lexical Embeddings to Improve Symbolic-Prosody Prediction in a Text-to-Speech Front End.*](https://ieeexplore.ieee.org/document/7472760){: external} Proceedings ICASSP (2016), pp. 5655-5659.
1.  <a id="slava2007" style="border-bottom:none">Shechtman, Slava.</a> [*Maximum-Likelihood Dynamic Intonation Model for Concatenative {{site.data.keyword.texttospeechshort}} System.*](http://www.isca-speech.org/archive_open/archive_papers/ssw6/ssw6_234.pdf){: external} Proceedings of the Sixth ISCA Workshop on Speech Synthesis (August 2007): pp. 234-239.
1.  <a id="shuang2006" style="border-bottom:none">Shuang, Zhi-Wei, Raimo Bakis, Slava Shechtman, Dan Chazan, and Yong Qin.</a> [*Frequency warping based on mapping formant parameters.*](https://www.researchgate.net/profile/Slava_Shechtman/publication/221491579_Frequency_warping_based_on_mapping_formant_parameters/links/55d462dd08ae7fb244f60c61.pdf){: external} Proceedings of the Ninth International Conference on Spoken Language Processing (ICSLP), Interspeech (2006): pp. 2290-2293.
